<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[XLNet理解]]></title>
    <url>%2F2019%2F07%2F11%2FXL_net%2F</url>
    <content type="text"><![CDATA[XLNet理解[TOC] 原文链接: XLNet: Generalized Autoregressive Pretraining for Language Understanding 两个概念自回归（AR）自回归语言模型：预测整个句子的概率分布，基于前面词预测下一个词的概率 代表：ELMO，GPT 优点：预测整个文本的概率分布，能更好捕捉文本的依存及序列关系 缺点：有些任务（如阅读理解）需要上下文来共同理解，只能依据前文信息，不能捕捉上下文关系 （上述感觉有点矛盾，句子的极大似然有点在于？？） 自编码（AE）自编码语言模型：对句子打乱先编码成低维特征，再通过decoder对打乱部分解码。 代表：BERT 优点：可捕捉到上下文信息 缺点：没有估计整个句子的极大似然，而只是将打乱的句子进行重构？？？ Motivation文章主要和BERT模型比较，因此针对BERT的缺点进行分析： BERT问题： 由于预训练阶段有【mask】字符，而在fine-tune阶段是没有的，导致了预训练和fine-tune阶段的数据差异 bert是直接对预测字符进行【mask】，但mask字符之间应该还存在依赖关系，但bert直接忽略了。 综上描述，本文提出XLNet模型，结合了自回归和自编码语言模型各自的优点，并改进了bert的问题。 XLNet采用自回归方式进行训练，同时结合上下文信息。 上下文信息的获取并不是像bert直接【mask】预测字符，而是通过“打乱”句子词的顺序来获得，并在attention层采用特定mask方式来预测乱序序列的极大似然。 另创新: 采用transfomerXL来作编码器，集成了片段循环和相对位置编码，相对位置编码对长文本更有用 基于本文的乱序语言模型调整了TransformerXL参数 XLNetPermutaion language modeling对于一个长度为N的序列，其全排列共有n！种方式。XLNet并不是只基于原始输入序列来预测该序列的极大似然，而是采样原始序列的不同排列方式来预测，由于不同排列方式包含了一个词的上下文信息，因此XLNet模型可捕捉到文本的上下文信息。 如上图：对于原始序列1,2,3,4. 采样了4种排列方式，当预测的字符是3时，对于4,3,1,2序列，3可基于其下文4来预测，而对于1,4,2,3,序列，3可得到所有上下文信息。由于模型的参数是不变的，因此，选择不同排列方式进行训练，h3位置的隐层信息会结合所有的序列上下文信息。 需要注意的是：这里乱序并不是真正的输入序列乱序，预训练时输入序列仍然是1,2,3,4序列，其“打乱”是通过attention层 mask方式来获得打乱序列。为什么不直接对输入序列进行打乱，作者说是为了保持预训练和fine-tune阶段统一，fine-tune阶段并不会将序列乱序输入。 XLNET语言模型目标： max_{\theta} E_z \left[ \sum^T_{t-1}\log_{P_{\theta}}(x_{z_t}|x_{zc}|x_{z\leq c})\right]=E_z\left[\sum^T_{t=c+1}\log_{P_{\theta}}(x_{z_t}|x_{z]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>modelSummary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[语言模型系列（BERT，ELMO,GTP,XLNET）]]></title>
    <url>%2F2019%2F06%2F30%2Fdynamic_languageMODEL%2F</url>
    <content type="text"><![CDATA[BERT仅接一个输出层即可state of art ELMO,GPT缺陷：仅是单向的语言模型，ELMO属于独立的左到右和右到左训练，GTP是采用transfomer的decoder部分，仅是根据前面的token来预测当前词。而单向的对于QA类任务远远不够，so,提出bert双向model 微调优点：需要重新训练的参数较少。 bert结构 双向mask语言模型（仅预测mask词）+下一句预测任务（sentence拼接，sep分隔，开头CLS词预测是/否下一句） 输入：sequence字符+第1/2个片段+位置embedding MLM部分：仅预测mask字符， 缺点： 预训练和微调时有影响，微调时看不见mask部分？？？（解决：取15%mask，mask中取80%替换成【mask】token,10%随机替换成另外一个词，10%保持不变。由于随机替换另外一个词仅1.5%，所以不影响。） 由于每个batch仅预测15%的词，so，收敛慢，但是效果好啊！！！ NSP（下一句预测部分）形式：CLS+S1+[sep]+s2,用CLS字符来预测next/not next 训练过程 使用完整的文档而非片段句子作为语料。 取2个句子，后一个句子50%替换成非下一句 seqence：512个token _gelu激活_，drop0.1,ADam loss:MLM+NSP任务最大似然取平均。 文中描述bert和gtp训练区别 语料：除了采用800MBooksCorpus，还用了WIKIoedia2500M word训练 使用CLS和SEP字符，GPT仅在微调阶段运用了，BERT在预训练阶段也用 对于1M步，GPT一个batch有32000个词，BERT有128000个词 GPT在所有的微调都使用学习率为5e-5，BERT是验证集找最好的学习率。 ELMO解决问题一词多义问题，动态词向量 要点 深度双向lstm语言模型 融合预训练各层词的状态（高层：语义相关，低层：语法相关） 语言模型目标函数：以整个句子为单位预测句子概率 每层词向量归一化相加*权重 ELMO_K=r\sum_{j=0}^Ls_jh_m^{k,j}r为缩放因子，实验证明很有用。 输入：字符级别cnn卷积 第一层到有第二层用到剩余连接 隐层4096，映射512维，字符嵌入=2048（n_gram卷积+highway） GPT为什么用语言模型——具体任务标注数据有限。 词表示学习2个挑战 不明确什么优化目标适合迁移 无统一且有效的方法去迁移 So，提出模型： transfomer 变种decoder部分（仅mask attention+前馈），因为lstm捕捉到的距离有限 语言模型目标：窗口词最大似然 fine_tune目标：具体任务目标+入*语言模型目标（作为辅助目标：加速收敛，提高性能） XLNET特点序列的最大似然估计（自回归语言模型目标函数）+双向文本信息 做法 乱序来捕捉上下文信息 乱序通过two-stream实现。 two-stream采用两种输入和隐层方式：一种是g（仅有序列前面词的文本信息和当前词的位置信息），一种是h（和bert方式一样） 采用两种方式保留了预测字符之间的依赖关系。 相对于bert改进 用于transformerXL，可捕捉更长距离依赖关系 采用attention mask解决了bert预训练和fine-tune阶段输入不一致问题,以及mask token间的依赖问题 用Two-stream解决了[mask] token的位置依赖信息。 再次总结 为了避免bert预训练和fine-tune不一致问题，XLNet并不采用输入mask方式，而是在attention做mask，还说bert解决fine-tune看不到mask的方式是随机替换别的词或保持不变，但这个几率太小了。 也为了解决基于自回归方法预测，模型采用two-tream方式来做]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>modelSummary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本蕴含部分论文总结]]></title>
    <url>%2F2019%2F06%2F15%2Fentailment_partone%2F</url>
    <content type="text"><![CDATA[Multi-Task Deep Neural Networks for Natural Language UnderstandingMT-DNN模型 基于bert的多任务微调 将GLUE的9个数据集分成4个任务 单句预测（句子语法判断COLA，情感分析SST-2） 文本相似度（相似度分数STS-B） 成对句子分类（文本蕴含RTE、MNLI，释义识别QQP，MRPC） 相关性排序任务（句子对排序QNLI） 模型架构 embedding：embedding+self attention encoder：底层bert微调，采用和bert相同输入方式，单句：CLS+句子；双句：CLS+句1+SEP+句2 任务层：不同任务采用不同预测方式+损失 单句分类：softmax+交叉熵 文本相似度：sigmoid+MSE 成对句子分类：SAN网络中多步匹配推理+交叉熵（作者自己的文章） 相关性排序：sigmoid+正例负对数似然 训练方式 所有的数据一起，不同类型的任务选择不同的损失方式一次训练 实验测试 当然是好过bert啦 由于前文提到多任务的好处之一是少量标签数据，这里在SNLI和scitail上分别做了取0.1%，1%，10%来预测，发现多任务训练在少量标签数据效果远好于bert。 Stochastic Answer Network for NLI（SAN）创新点 多步推理策略，对最终结果句向量采用多步推理，每步的结果预测一个结果，T步结果取平均。 模型架构 embedding层：300维CNNchar+300为glove encoder：双层biLSTM分别编码 记忆模块：对上层文本编码先relu映射再点积，同decompAtt拼接，再用一层bistm编码 答案预测：采用（假设，前提假设之间的交互）句向量进行多步推理 初始状态为 假设 自注意力加权s0， 输入为 假设和 前提矩阵和假设向量交互结果 拼接 得到新的状态st，再用于下一步假设向量输入 每一步由 [假设，前提交互，假设-前提交互，假设*前提交互 ]输出结果，预测类标 总T步类标取平均 模型trick：在预测结果采用dropout加强泛化。 Convolutional Spatial Attention Model for Reading Comprehension with Multiple-Choice Questions可取点：lstm+cnn提取特征结合 论文中阐述创新点：​ 1. 计算候选答案的不同类型的表示 ​ 2. 在计算注意力时，应用额外的训练参数来动态调整注意力的值，使之更加灵活 ​ 3. 使用每个层级的注意力结构来共同预测。 模型架构本文模型提出CSA（空间卷积注意力）充分利用层级注意力信息来做多选题阅读理解 编码层：编码了passage，问题Q和候选答案C的 词向量+ELMO+POS词性特征+匹配特征。 丰富候选答案的表示：合并passage，问题和三者之间的注意力交互信息。 ​ 本文重点在这里！用Fusion-Net思想，将C和Q,C和P，Q和P分别融合，再额外将QP和Q本身信息融合 R_{CQ}=g(B_C,B_Q), R_{CP}=g(B_C,B_P), R_{QP}=g(B_Q,B_P), R_{self-Q}=g(B_Q,B_{QP})​ 融合方式类似于双线性，再将融合信息CQ,CP,C分别和self-Q，QP做点积,直接将6个点积信息连接 抽取特征表示：使用卷积动态总结相邻窗口的信息。 将上述连接信息分别用3个卷积核5,10,15提取特征，提取的特征用来预测每一个候选答案是答案的可能性，将所有可能性softmax分类。 APPLYING DEEP LEARNING TO ANSWER SELECTION: A STUDY AND AN OPEN TASK本文重点 hinge loss运用 提出几种siamese cnn架构并做比较 Cnn优势 稀疏交互：传统的NN每个输入都和输出有关，但CNN输出部分仅是通过filter和input的局部窗口交互。 权重共享：filter权重共享，但传统参数仅用来计算一次 等量表示（Equivariant representation）：和max-pooling思想有关。 simese架构： 单层全连接+tanh编码，cnn抽取特征，maxpooling+tanh用于池化，cos计算相似度 1架构的权重共享 在1后增加隐层，并比较权重共享 多层cnn和多个过滤器比较 hinge loss思想 L=max（0,m-cos(V_Q,V_A+)+cos(V_Q,V_A-)）当正例-负例&gt;margin，即分类正确，损失=0 当&lt;margin,表明区分度不够大，损失=本身或-本身，目的要损失最小。 结论： 抽取特征用共享权重层比单独抽取效果更好（感觉是否因为这种句子对匹配任务，需要相同的权重去进一步比较，可能还和最后算cos有关，需要向量再同一空间） 在抽取完特征后增加一个隐层再算cos效果更差，说是cnn已经可以抽取到匹配特征。 增加cnn过滤器数量可一定程度增加效果 增加cnn层数也可一定程度增加效果 几种相似度量方法： cos l1范数：绝对值，沿着坐标轴方向相加 l2范数：欧氏距离，两坐标直线距离 内积：两向量之间的夹角 相似度度量结论： 和cos比较，l2和内积效果更好，l1效果更差。 作者提出，基于l2和内积(点乘)结合方式 乘法结合：欧式距离*内积方式 +参数调节 加法结合：欧式距离+内积方式 +参数调节 乘法效果会稍好。 Multi-Perspective Sentence Similarity Modeling with Convolutional Neural Networks全文思想 采用2种过滤器方式，3个过滤宽度，3中池化方式，对不同输出采用对应的相似度计算 模型架构：​ 过滤器方式：1. 对每个词向量总维度 ​ 2. 对词向量每一维 ​ 过滤宽度：上述两种方式分别采用宽度为1,2,3，和全部词长度宽度大小。 ​ 池化方式：max，min，aver ​ 相似度：采用cos和欧氏距离共同度量。 ​ 分别对不同的过滤及池化方式采用对应的相似度计算。 UMD-TTIC-UW at SemEval-2016 Task 1: Attention-Based Multi-Perspective Convolutional Neural Networks for Textual Similarity Measurement全文思想 基于上文MPCNN架构，上文是基于siamese结构，输入都是独立的句子，本文则在输入之前将两个句子交互。 输入交互方式即词词交互，并将交互矩阵和原词进行点积操作并和原词拼接作为输入。 A COMPARE-AGGREGATE MODEL FOR MATCHING TEXT SEQUENCES文中提及本文重点1.比较不同聚合函数，2.采用cnn提取特征 模型结构 更改版LSTM编码，仅用输入门 采用Q前馈+A点积方式计算注意力矩阵 重点比较不同的聚合函数，本文提出6种 最后用单层CNN提取特征并分类。 NATURAL LANGUAGE INFERENCE OVER INTERACTION SPACE（DIIN）模型思想提出DIIN网络，用denseNet来提取特征图 模型结构 embedding层：词向量+字符向量+词性特征+硬匹配特征 encoder：highway编码+自注意编码+gate编码（和highway同，就是不是1-g，而是2个gate） 特征交互层：方式为a*b 抽取匹配层：对上层交互特征（4维，最后a，b维相乘不相加）采用denseNet提取很多特征 输出层：线性分类器。 DRr-Net: Dynamic Re-read Network for Sentence Semantic Matching模型结构 堆叠GRUs 自匹配结构 Re-read结构（类似match-lstm，但并不是根据假设每一步循环，而是前提文本和带注意力的假设文本（一维向量）循环n次，作为re-read n次） 匹配层，相连，相减，相加 3个loss，上层分别计算3个匹配层：原假设结果匹配，read结果匹配，原+read再匹配结果。3个loss相加。]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>modelSummary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[残差相关论文小结]]></title>
    <url>%2F2019%2F06%2F10%2FreshighwaydenseNET%2F</url>
    <content type="text"><![CDATA[Densely Connected Convolutional Networks深层网络：Highway——ResNet——stochastic depth(ResNet 随机drop掉一些层)——DenseNet DenseNet优势： 缓解梯度消失 增强特征传播 加强特征重用 减少参数 文章要点 block中每层的输入和前面层的输出直接相连，因此，最后一层可看到前面所有层的结果。 在loss反传的时候可直接对前面层的结果求导，每层的输入可看成对前面特征的collection，减少需要学习的参数，和 ResNet的区别在于ResNet是相加方式，导致输入特征变化，参数重新学。？？相连不也要重新学？ 模型结构 3个Dense Block，transition layer间隔（1.改变特征图尺寸，2.摆脱dense block的瓶颈。） 每个dense block，BN—改进Relu—3*3Convd， 每个trainsition layer，BN—11Convd—2*2pooling base dense 3 block {40层，outputdim12，feamap3232}，{100层，outdim12，feamap16\16}，{100层，feamap8*8} BC denseNet {100层，outdim12，3232}，{250层，outdim24，16\16}，{190层，outdim40，8*8} 最后全局池化，softmax分类。初始convd层kernel7*7，stride=2 优点网络窄，参数少。 Deep Residual Learning for Image RecognitionResNet是为了解决深度网络degradation问题，（即层数增加，训练误差反而更大） 优势：在足够深的网络中易优化，同时增加精度。 Introduction文献表明：深度网络是有用的，堆叠更多层可捕获更丰富的特征。 但深度网络一个问题在于不容易优化，即出现梯度消失和爆炸问题， 解决方式是Normalization； 另一个问题是随着深度网络的增加，准确率却逐渐趋于饱和并开始下降，而这并非是过拟合现象，因为训练误差也随着层数增加而不断增大， 现有的解决方法是：增加相同的映射，其他层从已学习的浅层model中复制（啥意思？？）；但这种方法可使深层网络不出现更高的训练误差，但是其准确率并没有更好。 本文提出：深度残差网络，可解决上述问题。采用恒等映射（identiey mapping），对输入（identity）进行的shortcut连接，易优化是因为可直接对前输入进行梯度计算（x+F（x））。本文模型在…获得第一名，有效！ 残差分析 X_L=X_l+\sum_{i-1}^{L-1}F(x_i,W_i) 在误差经过反向传播后，为如下式子，恒等变换使得x可无损传播，残差的梯度在有1的存在也可避免梯度消失。 \frac{\partial_{Loss}}{\partial_{x_l}}=\frac{\partial_{Loss}}{\partial_{x_L}}\cdot(1+\frac{\partial}{\partial_{X_l}}\sum_{i-1}^{L-1}F(x_i,W_i)) 输出维度形同可采用恒等映射，维度不同可1、0填充，需先下采样，2、w映射到相同维度 残差学习对深网更有效，浅层效果不明显 skip connection和恒等映射最有用。 在前向阶段，输入可直接传到后层；反传阶段，误差可通过恒等映射直接传到浅层 预激活（BN和激活放到网络前面）效果会更好，可训练层数更深。 模型结构 32层残差，1层输入卷积，最后一层池化+全连接 输出大小相同则过滤器个数相同，特征图输出大小减半，则过滤器数加倍，以保持网络复杂度不变。 Highway Network思想通过门控机制来选择输入和输出进行连接。 y=H(x,W_H)\cdot T(x,W_T)+x\cdot (1-T(w,W_T))T是门控机制动态选择X和H的输出。由下，当门控为0/1只选择其中一个。 y=\begin{cases} x & if\ T(x,W_T)=0 \\ H(x,W_H) & if\ T(x,W_T)=1 \end{cases}反传时： \frac{\text{d}x}{\text{d}y}=\begin{cases} I & if\ T(x,W_T)=0 \\ H’(x,W_H) & if\ T(x,W_T)=1 \end{cases}每个block由state（输出H），和transform gate output组成，y。]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>modelSummary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RC论文整理]]></title>
    <url>%2F2019%2F03%2F11%2FMulti-Granularity%20Hierarchical%20Attention%20Fusion%20Networks%20for%20Reading%20Comprehension%20and%20Question%20Answering%2F</url>
    <content type="text"><![CDATA[《Multi-Granularity Hierarchical Attention Fusion Networks for Reading Comprehension and Question Answering》**框架架构：co-attention层+fusion，self层+fusion，pointer-net Encoder层： ELMO得到的字符嵌入和glove词向量拼接，用BiLSTM编码passage和question的文本向量，将编码的文本向量再和字符向量$c_t$拼接，得到passage和query的文本表示$u_t$。作者认为这里可以看作是不同层面的词表示的residual connection. u_t^Q=[BiLSTM_Q([e_t^Q,c_t^Q]),c_t^Q] u_t^P=[BiLSTM_P([e_t^P,c_t^P]),c_t^P]其中$ c_t$为ELMO语言模型生成的字符嵌入，而$ e_t$为glove词向量。​ 其中$ c_t$为ELMO语言模型生成的字符嵌入，而$ e_t$为glove词向量。 Hierarchical Attention &amp; Fusion层 这里的Hierarchical体现在co-attention和self-attention的结合上，且原表示和对齐后的表示能捕捉到文本不同粒度的语义信息，所以作者在每一个attention后用了连接融合。 Co-attention &amp;Fusion 计算词词软对齐矩阵:采用可并行的前馈点积方式。 S_{ij}=Att(u_t^Q,u_t^P)=ReLU(W_{lin}^Tu_t^Q)^T \cdot RuLU(W_{lin}^Tu_t^P) P2Q Attention 计算question每个词对passage每个词的重要性 a_{j}=softmax\left(S_{:j}\right),对齐passage表示$\tilde{Q}$由question表示加权相加而得 \tilde{Q}_{:t}=\sum_j\alpha_{tj}\cdot Q_{:j},\forall j\in[1,\ldots,m] Q2P Attention 计算和question词最相近的passage词，方法同上 $ \ \ \ \ \ \beta_i=softmax(S_{i:}) ,\ \ \ \ \ \ \tilde{P}_{:k}=\sum_i\beta_{ik} \cdot P_i,\forall i \in [1,\ldots,n]$ $\tilde{P}$表示和当前question词相关的passage词权重和 融合方式 P'=Fuse(P，\tilde{Q}) Q'=Fuse(Q,\tilde{P})其中，Fuse（，）为fusion kernel，作者在还选取了其他kernel的方式，并做了结果分析，有兴趣可以自己具体看论文 m(P,\tilde{Q})=tanh(W_f[P;\tilde{Q};P\circ\tilde{Q};P-\tilde{Q}]+b_f)由于作者发现原始上下文表示对全局语义表示十分重要，因此采用gate机制来合并原始上下文和新的对齐表示， P'=g(P,\tilde{Q})\cdot m(P,\tilde{Q})+(1-g(P,\tilde{Q}))\cdot P Q'=g(Q,\tilde{P})\cdot m(Q,\tilde{P})+(1-g(Q,\tilde{P}))\cdot Q self-attention &amp;Fusion层 自注意力层分别各自对齐 question和passage的全局表示 首先将手工构建的passage特征拼接到新的passage表示P’后，并将其通过BiLSTM, D=BiLSTM([P';feat_{manu}])通过双线性对齐 L=softmax(D\cdot W_1\cdot D^T) \tilde{D}=L\cdot D再一次使用fusion kernel融合 D'=Fuse(D,\tilde{D}) D''=BiLSTM(D')而对于question，由于长度相对较短，仅将其加权固定为向量 \gamma=softmax(w_q^T,Q'') q=\sum_j\gamma_j\cdot Q_{:j}'',\forall j\in[1,\ldots,m] output层 采用双线性match来预测passage的开始和结束词作为答案片段 P_{start}=softmax(q\cdot W_s^T\cdot D'') P_{end}=softmax(q\cdot W_e^T\cdot D'') 采用$P_s$和$P_e$的负对数似然作为损失函数 在预测阶段，选择最大的$P_s\cdot P_e$作为答案片段，其中s&lt;=e&lt;=s+15 Ablation结果分析 1&#123;% qnimg slqa_ablation.png %&#125; 其中BI-linear Match作用最大，其次是Elmo得到的字符向量。]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>modelSummary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test]]></title>
    <url>%2F2019%2F03%2F11%2Ftest%2F</url>
    <content type="text"><![CDATA[《Iterative Alternating Neural Attention for Machine Reading》Inference(推理阶段)旨在处理文本和查询复杂的语义关系，为答案预测提供强有力的证据。使用迭代过程完成，每次迭代处理document和query信息并存储起来，最终，利用迭代存储的记忆信息预测答案。 对query和document 双向GRU编码, 对query和document进行迭代推理， Q i，t为添加注意力权重的query，用原qi和第t-1轮推理向量st-1进行双线性匹配加偏置 Di，t为添加注意力权重的document，用原q和d和前一步推S t-1理得到 m(P,\tilde{Q})=tanh(W_f[P;\tilde{Q};P\circ\tilde{Q};P-\tilde{Q}]+b_f) a_{j}=softmax\left(S_{:j}\right),]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>modelSummary</tag>
        <tag>test</tag>
      </tags>
  </entry>
</search>
