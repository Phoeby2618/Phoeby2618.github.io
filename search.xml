<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[testtest]]></title>
    <url>%2F2019%2F07%2F12%2Ftesttest%2F</url>
    <content type="text"><![CDATA[第22个测试。。。]]></content>
  </entry>
  <entry>
    <title><![CDATA[XLNet理解]]></title>
    <url>%2F2019%2F07%2F11%2Ftt%2F</url>
    <content type="text"><![CDATA[[TOC] 原文链接: XLNet: Generalized Autoregressive Pretraining for Language Understanding 两个概念自回归（AR）自回归语言模型：预测整个句子的概率分布，基于前面词预测下一个词的概率 代表：ELMO，GPT 优点：预测整个文本的概率分布，能更好捕捉文本的依存及序列关系 缺点：有些任务（如阅读理解）需要上下文来共同理解，只能依据前文信息，不能捕捉上下文关系 （上述感觉有点矛盾，句子的极大似然有点在于？？） 自编码（AE）自编码语言模型：对句子打乱先编码成低维特征，再通过decoder对打乱部分解码。 代表：BERT 优点：可捕捉到上下文信息 缺点：没有估计整个句子的极大似然，而只是将打乱的句子进行重构？？？ Motivation文章主要和BERT模型比较，因此针对BERT的缺点进行分析： BERT问题： 由于预训练阶段有【mask】字符，而在fine-tune阶段是没有的，导致了预训练和fine-tune阶段的数据差异 bert是直接对预测字符进行【mask】，但mask字符之间应该还存在依赖关系，但bert直接忽略了。 综上描述，本文提出XLNet模型，结合了自回归和自编码语言模型各自的优点，并改进了bert的问题。 XLNet采用自回归方式进行训练，同时结合上下文信息。 上下文信息的获取并不是像bert直接【mask】预测字符，而是通过“打乱”句子词的顺序来获得，并在attention层采用特定mask方式来预测乱序序列的极大似然。 另创新: 采用transfomerXL来作编码器，集成了片段循环和相对位置编码，相对位置编码对长文本更有用 基于本文的乱序语言模型调整了TransformerXL参数 XLNetPermutaion language modeling对于一个长度为N的序列，其全排列共有n！种方式。XLNet并不是只基于原始输入序列来预测该序列的极大似然，而是采样原始序列的不同排列方式来预测，由于不同排列方式包含了一个词的上下文信息，因此XLNet模型可捕捉到文本的上下文信息。 如上图：对于原始序列1,2,3,4. 采样了4种排列方式，当预测的字符是3时，对于4,3,1,2序列，3可基于其下文4来预测，而对于1,4,2,3,序列，3可得到所有上下文信息。由于模型的参数是不变的，因此，选择不同排列方式进行训练，h3位置的隐层信息会结合所有的序列上下文信息。 需要注意的是：这里乱序并不是真正的输入序列乱序，预训练时输入序列仍然是1,2,3,4序列，其“打乱”是通过attention层 mask方式来获得打乱序列。为什么不直接对输入序列进行打乱，作者说是为了保持预训练和fine-tune阶段统一，fine-tune阶段并不会将序列乱序输入。 XLNET语言模型目标： max_{\theta} E_z \left[ \sum^T_{t-1}\log_{P_{\theta}}(x_{z_t}|x_{zc}|x_{z\leq c})\right]=E_z\left[\sum^T_{t=c+1}\log_{P_{\theta}}(x_{z_t}|x_{z]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>modelSummary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XLNet理解]]></title>
    <url>%2F2019%2F07%2F11%2FXL_net%2F</url>
    <content type="text"><![CDATA[XLNet理解[TOC] 原文链接: XLNet: Generalized Autoregressive Pretraining for Language Understanding 两个概念自回归（AR）自回归语言模型：预测整个句子的概率分布，基于前面词预测下一个词的概率 代表：ELMO，GPT 优点：预测整个文本的概率分布，能更好捕捉文本的依存及序列关系 缺点：有些任务（如阅读理解）需要上下文来共同理解，只能依据前文信息，不能捕捉上下文关系 （上述感觉有点矛盾，句子的极大似然有点在于？？） 自编码（AE）自编码语言模型：对句子打乱先编码成低维特征，再通过decoder对打乱部分解码。 代表：BERT 优点：可捕捉到上下文信息 缺点：没有估计整个句子的极大似然，而只是将打乱的句子进行重构？？？ Motivation文章主要和BERT模型比较，因此针对BERT的缺点进行分析： BERT问题： 由于预训练阶段有【mask】字符，而在fine-tune阶段是没有的，导致了预训练和fine-tune阶段的数据差异 bert是直接对预测字符进行【mask】，但mask字符之间应该还存在依赖关系，但bert直接忽略了。 综上描述，本文提出XLNet模型，结合了自回归和自编码语言模型各自的优点，并改进了bert的问题。 XLNet采用自回归方式进行训练，同时结合上下文信息。 上下文信息的获取并不是像bert直接【mask】预测字符，而是通过“打乱”句子词的顺序来获得，并在attention层采用特定mask方式来预测乱序序列的极大似然。 另创新: 采用transfomerXL来作编码器，集成了片段循环和相对位置编码，相对位置编码对长文本更有用 基于本文的乱序语言模型调整了TransformerXL参数 XLNetPermutaion language modeling对于一个长度为N的序列，其全排列共有n！种方式。XLNet并不是只基于原始输入序列来预测该序列的极大似然，而是采样原始序列的不同排列方式来预测，由于不同排列方式包含了一个词的上下文信息，因此XLNet模型可捕捉到文本的上下文信息。 如上图：对于原始序列1,2,3,4. 采样了4种排列方式，当预测的字符是3时，对于4,3,1,2序列，3可基于其下文4来预测，而对于1,4,2,3,序列，3可得到所有上下文信息。由于模型的参数是不变的，因此，选择不同排列方式进行训练，h3位置的隐层信息会结合所有的序列上下文信息。 需要注意的是：这里乱序并不是真正的输入序列乱序，预训练时输入序列仍然是1,2,3,4序列，其“打乱”是通过attention层 mask方式来获得打乱序列。为什么不直接对输入序列进行打乱，作者说是为了保持预训练和fine-tune阶段统一，fine-tune阶段并不会将序列乱序输入。 XLNET语言模型目标： max_{\theta} E_z \left[ \sum^T_{t-1}\log_{P_{\theta}}(x_{z_t}|x_{zc}|x_{z\leq c})\right]=E_z\left[\sum^T_{t=c+1}\log_{P_{\theta}}(x_{z_t}|x_{z]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>modelSummary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RC论文整理]]></title>
    <url>%2F2019%2F03%2F11%2FMulti-Granularity%20Hierarchical%20Attention%20Fusion%20Networks%20for%20Reading%20Comprehension%20and%20Question%20Answering%2F</url>
    <content type="text"><![CDATA[《Multi-Granularity Hierarchical Attention Fusion Networks for Reading Comprehension and Question Answering》**框架架构：co-attention层+fusion，self层+fusion，pointer-net Encoder层： ELMO得到的字符嵌入和glove词向量拼接，用BiLSTM编码passage和question的文本向量，将编码的文本向量再和字符向量$c_t$拼接，得到passage和query的文本表示$u_t$。作者认为这里可以看作是不同层面的词表示的residual connection. u_t^Q=[BiLSTM_Q([e_t^Q,c_t^Q]),c_t^Q] u_t^P=[BiLSTM_P([e_t^P,c_t^P]),c_t^P]其中$ c_t$为ELMO语言模型生成的字符嵌入，而$ e_t$为glove词向量。​ 其中$ c_t$为ELMO语言模型生成的字符嵌入，而$ e_t$为glove词向量。 Hierarchical Attention &amp; Fusion层 这里的Hierarchical体现在co-attention和self-attention的结合上，且原表示和对齐后的表示能捕捉到文本不同粒度的语义信息，所以作者在每一个attention后用了连接融合。 Co-attention &amp;Fusion 计算词词软对齐矩阵:采用可并行的前馈点积方式。 S_{ij}=Att(u_t^Q,u_t^P)=ReLU(W_{lin}^Tu_t^Q)^T \cdot RuLU(W_{lin}^Tu_t^P) P2Q Attention 计算question每个词对passage每个词的重要性 a_{j}=softmax\left(S_{:j}\right),对齐passage表示$\tilde{Q}$由question表示加权相加而得 \tilde{Q}_{:t}=\sum_j\alpha_{tj}\cdot Q_{:j},\forall j\in[1,\ldots,m] Q2P Attention 计算和question词最相近的passage词，方法同上 $ \ \ \ \ \ \beta_i=softmax(S_{i:}) ,\ \ \ \ \ \ \tilde{P}_{:k}=\sum_i\beta_{ik} \cdot P_i,\forall i \in [1,\ldots,n]$ $\tilde{P}$表示和当前question词相关的passage词权重和 融合方式 P'=Fuse(P，\tilde{Q}) Q'=Fuse(Q,\tilde{P})其中，Fuse（，）为fusion kernel，作者在还选取了其他kernel的方式，并做了结果分析，有兴趣可以自己具体看论文 m(P,\tilde{Q})=tanh(W_f[P;\tilde{Q};P\circ\tilde{Q};P-\tilde{Q}]+b_f)由于作者发现原始上下文表示对全局语义表示十分重要，因此采用gate机制来合并原始上下文和新的对齐表示， P'=g(P,\tilde{Q})\cdot m(P,\tilde{Q})+(1-g(P,\tilde{Q}))\cdot P Q'=g(Q,\tilde{P})\cdot m(Q,\tilde{P})+(1-g(Q,\tilde{P}))\cdot Q self-attention &amp;Fusion层 自注意力层分别各自对齐 question和passage的全局表示 首先将手工构建的passage特征拼接到新的passage表示P’后，并将其通过BiLSTM, D=BiLSTM([P';feat_{manu}])通过双线性对齐 L=softmax(D\cdot W_1\cdot D^T) \tilde{D}=L\cdot D再一次使用fusion kernel融合 D'=Fuse(D,\tilde{D}) D''=BiLSTM(D')而对于question，由于长度相对较短，仅将其加权固定为向量 \gamma=softmax(w_q^T,Q'') q=\sum_j\gamma_j\cdot Q_{:j}'',\forall j\in[1,\ldots,m] output层 采用双线性match来预测passage的开始和结束词作为答案片段 P_{start}=softmax(q\cdot W_s^T\cdot D'') P_{end}=softmax(q\cdot W_e^T\cdot D'') 采用$P_s$和$P_e$的负对数似然作为损失函数 在预测阶段，选择最大的$P_s\cdot P_e$作为答案片段，其中s&lt;=e&lt;=s+15 Ablation结果分析 1&#123;% qnimg slqa_ablation.png %&#125; 其中BI-linear Match作用最大，其次是Elmo得到的字符向量。]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>modelSummary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test]]></title>
    <url>%2F2019%2F03%2F11%2Ftest%2F</url>
    <content type="text"><![CDATA[《Iterative Alternating Neural Attention for Machine Reading》Inference(推理阶段)旨在处理文本和查询复杂的语义关系，为答案预测提供强有力的证据。使用迭代过程完成，每次迭代处理document和query信息并存储起来，最终，利用迭代存储的记忆信息预测答案。 对query和document 双向GRU编码, 对query和document进行迭代推理， Q i，t为添加注意力权重的query，用原qi和第t-1轮推理向量st-1进行双线性匹配加偏置 Di，t为添加注意力权重的document，用原q和d和前一步推S t-1理得到 m(P,\tilde{Q})=tanh(W_f[P;\tilde{Q};P\circ\tilde{Q};P-\tilde{Q}]+b_f) a_{j}=softmax\left(S_{:j}\right),]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>modelSummary</tag>
        <tag>test</tag>
      </tags>
  </entry>
</search>
